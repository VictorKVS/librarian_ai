# -*- coding: utf-8 -*-
# üìÑ –§–∞–π–ª: embedder.py
# üìÇ –ü—É—Ç—å: core/tools/embedder.py
# üìå –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é Sentence-Transformers

from typing import List, Optional, Union
import logging
import numpy as np

try:
    from sentence_transformers import SentenceTransformer
except ImportError:
    raise ImportError(
        "SentenceTransformer –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–∞–∫–µ—Ç:\n"
        "    pip install sentence-transformers"
    )

# –õ–æ–≥–≥–µ—Ä
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

class EmbeddingService:
    """
    –°–µ—Ä–≤–∏—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è —Ç–µ–∫—Å—Ç–∞.

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç SentenceTransformer (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'all-MiniLM-L6-v2').
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–¥–∏–Ω–æ—á–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ –±–∞—Ç—á–∏. –ï—Å—Ç—å –æ–ø—Ü–∏—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–µ–∫—Ç–æ—Ä–æ–≤.

    –ü—Ä–∏–º–µ—Ä:
        embedder = EmbeddingService()
        vec = embedder.embed_text("–ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞")
        batch = embedder.embed_batch(["—Ç–µ–∫—Å—Ç 1", "—Ç–µ–∫—Å—Ç 2"])
    """

    def __init__(
        self,
        model_name: str = "all-MiniLM-L6-v2",
        device: str = "cpu",
        normalize_embeddings: bool = True,
        **model_kwargs
    ):
        self.model_name = model_name
        self.device = device
        self.normalize_embeddings = normalize_embeddings
        self.model_kwargs = model_kwargs

        logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {model_name} ‚Üí {device}")
        try:
            self.model = SentenceTransformer(model_name, device=device, **model_kwargs)
            # –ü—Ä–æ–±–Ω—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥
            test_vec = self.model.encode("—Ç–µ—Å—Ç", normalize_embeddings=normalize_embeddings)
            self.embedding_dim = test_vec.shape[0]
            logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ. –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–≤: {self.embedding_dim}")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏: {e}")
            raise

    def embed_text(
        self,
        text: str,
        normalize: Optional[bool] = None,
        convert_to_numpy: bool = True
    ) -> Union[List[float], np.ndarray]:
        """
        –≠–º–±–µ–¥–¥–∏–Ω–≥ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ —Ç–µ–∫—Å—Ç–∞.

        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è.
            normalize: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (–∏–Ω–∞—á–µ ‚Äî –∏–∑ init).
            convert_to_numpy: –í–µ—Ä–Ω—É—Ç—å np.array –∏–ª–∏ list.

        Returns:
            –í–µ–∫—Ç–æ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–∞.
        """
        if not isinstance(text, str) or not text.strip():
            raise ValueError("–¢–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–µ–ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–æ–π.")

        normalize = self.normalize_embeddings if normalize is None else normalize

        try:
            vec = self.model.encode(
                text,
                normalize_embeddings=normalize,
                convert_to_tensor=False,
                show_progress_bar=False
            )
            return np.array(vec) if convert_to_numpy else vec
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —Ç–µ–∫—Å—Ç–∞: {e}")
            raise

    def embed_batch(
        self,
        texts: List[str],
        batch_size: int = 32,
        normalize: Optional[bool] = None,
        convert_to_numpy: bool = True
    ) -> Union[np.ndarray, List[List[float]]]:
        """
        –≠–º–±–µ–¥–¥–∏–Ω–≥ —Å–ø–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤.

        Args:
            texts: –°–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫.
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞.
            normalize: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è.
            convert_to_numpy: –í–µ—Ä–Ω—É—Ç—å np.array –∏–ª–∏ list of lists.

        Returns:
            –ú–∞—Å—Å–∏–≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.
        """
        if not isinstance(texts, list) or not all(isinstance(t, str) for t in texts):
            raise ValueError("texts –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º —Å—Ç—Ä–æ–∫.")

        normalize = self.normalize_embeddings if normalize is None else normalize

        try:
            result = self.model.encode(
                texts,
                batch_size=batch_size,
                normalize_embeddings=normalize,
                convert_to_tensor=False,
                show_progress_bar=False
            )
            return np.array(result) if convert_to_numpy else result
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –±–∞—Ç—á-—ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
            raise

    def get_embedding_dimension(self) -> int:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.
        """
        return self.embedding_dim

    def __repr__(self):
        return (
            f"<EmbeddingService(model_name={self.model_name}, "
            f"device={self.device}, "
            f"embedding_dim={self.embedding_dim})>"
        )
